pre-commit
torch==2.8.0
torchaudio==2.8.0
torchvision==0.23.0
transformers==4.57.1
qwen-vl-utils==0.0.11
datasets
setuptools
tqdm
wandb
psutil
numpy
accelerate
pydantic
sglang[all]==0.5.4
openai-harmony
flash-attn>=2.6.3
flash-attn-cute @ git+https://github.com/Dao-AILab/flash-attention.git@54d8aa6751fc9d5f0357854079261913d5df1f9d#subdirectory=flash_attn/cute
